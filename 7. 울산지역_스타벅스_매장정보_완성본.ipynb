{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82823a8",
   "metadata": {},
   "source": [
    "# 스타벅스 매장 정보 스크래핑(울산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1219638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import bs4\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 크롬 브라우저 실행\n",
    "driver = webdriver.Chrome(\"C:/Users/admin/chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "#크롬 브라우저에서 스타벅스 매장 정보 싸이트에 접속하고 코드를 작성!\n",
    "driver.get('https://www.starbucks.co.kr/store/store_map.do')\n",
    "\n",
    "#싸이트 접속 후 3초간 대기하는 코드를 작성!\n",
    "time.sleep(3)\n",
    "\n",
    "# 지역 검색 버튼을 찾는 코드를 작성\n",
    "loca = driver.find_element(By.CLASS_NAME, \"loca_search\")\n",
    "\n",
    "# 찾은 버튼을 클릭하는 코드를 작성\n",
    "loca.click()\n",
    "\n",
    "#3초가 대기한다.\n",
    "time.sleep(3)\n",
    "\n",
    "# 시/도 정보가 위치한 태그를 찾는 코드 작성\n",
    "sido = driver.find_element(By.CLASS_NAME, 'sido_arae_box')\n",
    "\n",
    "# 시/도 정보가 위치한 태그 안의 모든 li 태그를 찾는 코드 작성\n",
    "li = sido.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "# 울산 지역의 <li>태그를 클릭한다. \n",
    "# python은 숫자를 샐 때 0부터 시작한다.!\n",
    "li[6].click()\n",
    "\n",
    "# 3초간 대기\n",
    "time.sleep(3)\n",
    "\n",
    "# 구/군 정보가 위치한 태그를 찾는 코드 작성\n",
    "gugun = driver.find_element(By.CLASS_NAME,'gugun_arae_box')\n",
    "\n",
    "# 구/군 정보가 위치한 태그 안에서 전체 구군에 대한 \n",
    "# li 태그를 찾는 코드 작성\n",
    "total_gugun = gugun.find_element(By.TAG_NAME, \"li\") \n",
    "\n",
    "# 찾은 태그 클릭\n",
    "total_gugun.click()\n",
    "\n",
    "#3초간 대기\n",
    "time.sleep(3)\n",
    "\n",
    "# 현재 열려 있는 페이지의 모든 정보를 BeautifulSoup 형태로 변환(BeautifulSoup으로 변환하면 데이터를 가져 오지 편하다.)\n",
    "bs = bs4.BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "#매장 이름이 있는 태그를 선택한다.(class가 loca_step3인 div태그를 선택)\n",
    "entire=bs.find('div', class_='loca_step3')\n",
    "\n",
    "#찾은 태그 안에서 li태그를 모두 선택한다.\n",
    "li_list = entire.findAll('li')\n",
    "\n",
    "# 스크래핑한 데이터를 엑셀로 추출하기 위한 작업 시작!\n",
    "\n",
    "nameList = [] #매장명을 저장할 변수\n",
    "arrList = [] #매장의 주소를 저장할 변수\n",
    "tellList = [] #매장의 연락처를 저장할 변수\n",
    "\n",
    "#li_list의 개수만큼 반복을 시작한다.\n",
    "#li_list의 데이터를 하나씩 빼서 infor라는 이름을 부여한다.\n",
    "for infor in li_list:\n",
    "    #매장 이름을 추출\n",
    "    name = infor.find('strong').get_text()\n",
    "    \n",
    "    #추출한 매장 이름을 nameList에 추가\n",
    "    nameList.append(name)\n",
    "    \n",
    "    #매장 주소와 연락처 정보를 추출\n",
    "    arrAndTell = infor.find('p').get_text()\n",
    "   \n",
    "    #주소 정보만 추출\n",
    "    arr = arrAndTell[:-9]\n",
    "    \n",
    "    #추출한 주소 정보를 arrList에 추가\n",
    "    arrList.append(arr)\n",
    "    \n",
    "    #연락처 정보만 추출\n",
    "    tell = arrAndTell[-9:]\n",
    "    \n",
    "    #추출한 연락처 정보를 tellList 추가\n",
    "    tellList.append(tell)\n",
    "    # -- for문 종료!\n",
    "    \n",
    "#스크래핑한 모든 정보를 하나의데이터의 저장\n",
    "data = {\n",
    "    '상호명':nameList\n",
    "    , '주소':arrList\n",
    "    , '연락처':tellList\n",
    "}   \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#엑셀 파일로 저장\n",
    "df.to_excel('스타벅스_매장정보.xlsx')\n",
    "\n",
    "#완성된 출력\n",
    "df    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
